{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshamgarg/Augmenting-Dirichlet-Network/blob/main/simclr_features/Augmented_simclr_in_out.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyRiYUL6Bs0Y"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision\n",
        "from itertools import cycle\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18, resnet34\n",
        "from torchvision import transforms\n",
        "# import hydra\n",
        "# from omegaconf import DictConfig\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.datasets import CIFAR10, SVHN\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, resnet34\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJR3R663Bs0b",
        "outputId": "a98559dc-6a2f-49f4-92df-d6d0a619e993"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLau1wEGBs0b"
      },
      "outputs": [],
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_encoder, projection_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc = base_encoder(pretrained=False)  # load model from torchvision.models without pretrained weights.\n",
        "        self.feature_dim = self.enc.fc.in_features\n",
        "\n",
        "        # Customize for CIFAR10. Replace conv 7x7 with conv 3x3, and remove first max pooling.\n",
        "        # See Section B.9 of SimCLR paper.\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.enc.maxpool = nn.Identity()\n",
        "        self.enc.fc = nn.Identity()  # remove final fully connected layer.\n",
        "\n",
        "        # Add MLP projection.\n",
        "        self.projection_dim = projection_dim\n",
        "        self.projector = nn.Sequential(nn.Linear(self.feature_dim, 2048),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(2048, projection_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.enc(x)\n",
        "        projection = self.projector(feature)\n",
        "        return feature, projection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5phb4ItUBs0c"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "workers = 1\n",
        "backbone = 'resnet18'\n",
        "projection_dim = 128\n",
        "optimizer = 'sgd' \n",
        "learning_rate = 0.6 # initial lr = 0.3 * batch_size / 256\n",
        "momentum = 0.9\n",
        "weight_decay = 1.0e-6 # \"optimized using LARS [...] and weight decay of 10âˆ’6\"\n",
        "temperature = 0.5\n",
        "epochs = 1200\n",
        "log_interval = 50\n",
        "load_epoch = 700\n",
        "finetune_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx8GxhmTBs0d"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        \n",
        "class CIFAR10Pair(CIFAR10):\n",
        "    \"\"\"Generate mini-batche pairs on CIFAR10 training set.\"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.targets[idx]\n",
        "        img = Image.fromarray(img)  # .convert('RGB')\n",
        "        imgs = [self.transform(img), self.transform(img)]\n",
        "        return torch.stack(imgs), target  # stack a positive pair\n",
        "    \n",
        "class SVHNPair(SVHN):\n",
        "    \"\"\"Generate mini-batche pairs on CIFAR10 training set.\"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.labels[idx]\n",
        "        img = Image.fromarray(img)  # .convert('RGB')\n",
        "        imgs = [self.transform(img), self.transform(img)]\n",
        "        return torch.stack(imgs), target  # stack a positive pair\n",
        "    \n",
        "\n",
        "\n",
        "class CIFAR10_SVHN_Pair(CIFAR10):\n",
        "    \"\"\"Generate mini-batche pairs on CIFAR10 training set.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.data1 = data1.data\n",
        "        self.targets1 = data1.targets\n",
        "        self.data2 = data2.data\n",
        "        self.targets2 = data2.labels\n",
        "        \n",
        "        self.data = self.data1\n",
        "        self.targets = self.targets1\n",
        "        self.transform = train_transform\n",
        "#         self.data = data1.data \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        in_img, in_target = self.data1[idx], self.targets1[idx]\n",
        "        in_img = Image.fromarray(in_img)  # .convert('RGB')\n",
        "        in_imgs = [self.transform(in_img), self.transform(in_img)]\n",
        "        out_img, out_target = self.data2[idx], self.targets2[idx]\n",
        "        out_imgs = [self.transform(out_img), self.transform(out_img)]\n",
        "        return (torch.stack(in_imgs), torch.stack(out_imgs), in_target, out_target)  # stack a positive pair\n",
        "\n",
        "    \n",
        "def nt_xent(x_in, x_out, t=0.5):\n",
        "    x_in = F.normalize(x_in, dim=1)\n",
        "    x_in_scores = torch.dot(x_in[0], x_in[1])\n",
        "    \n",
        "    x_out = F.normalize(x_out, dim=1)\n",
        "    x_out_scores =  torch.dot(x_out[0], x_out[1])\n",
        "\n",
        "    loss = -torch.log(torch.exp(x_in_scores)) + (0.8 * torch.log(1 + torch.exp(x_out_scores) - torch.exp(x_in_scores)))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "    \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "\n",
        "# color distortion composed by color jittering and color dropping.\n",
        "# See Section A of SimCLR: https://arxiv.org/abs/2002.05709\n",
        "def get_color_distortion(s=0.5):  # 0.5 for CIFAR10 by default\n",
        "    # s is the strength of color distortion\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort\n",
        "\n",
        "# @hydra.main(config_path='/content/drive/MyDrive/CV_Project/simclr_config.yml')\n",
        "def train():\n",
        "    assert torch.cuda.is_available()\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    train_transform = transforms.Compose([transforms.RandomResizedCrop(32),\n",
        "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                          get_color_distortion(s=0.5),\n",
        "                                          transforms.ToTensor()])\n",
        "    train_set = CIFAR10Pair(root='./data',\n",
        "                            train=True,\n",
        "                            transform=train_transform,\n",
        "                            download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_set,\n",
        "                              batch_size=1,\n",
        "                              shuffle=True,\n",
        "                              num_workers=workers,\n",
        "                              drop_last=True)\n",
        "    train_out_set = SVHNPair(root='./data',\n",
        "                            split ='train',\n",
        "                            transform=train_transform,\n",
        "                            download=True)\n",
        "    \n",
        "    train_out_set.data = np.vstack(train_out_set.data).reshape(-1, 32, 32, 3)\n",
        "    train_out_set.data = train_out_set.data[0:50000]\n",
        "    train_out_set.labels = train_out_set.labels[0:50000]\n",
        "    train_out_loader = DataLoader(train_out_set,\n",
        "                              batch_size=1,\n",
        "                              shuffle=True,\n",
        "                              num_workers=workers,\n",
        "                              drop_last=True)\n",
        "    \n",
        "\n",
        "    # Prepare model\n",
        "    assert backbone in ['resnet18', 'resnet34']\n",
        "    base_encoder = eval(backbone)\n",
        "    model = SimCLR(base_encoder, projection_dim=projection_dim).cuda()\n",
        "#     checkpoint = torch.load('CV_Project/simclr/simclr_resnet18_epoch400.pt')\n",
        "    model.load_state_dict(torch.load('CV_Project/simclr/simclr_resnet18_epoch1200.pt'), strict=False)\n",
        "    logger.info('Base model: {}'.format(backbone))\n",
        "    logger.info('feature dim: {}, projection dim: {}'.format(model.feature_dim, projection_dim))\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay,\n",
        "        nesterov=True)\n",
        "\n",
        "    # cosine annealing lr\n",
        "    scheduler = LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "            step,\n",
        "            epochs * len(train_loader),\n",
        "            learning_rate,  # lr_lambda computes multiplicative factor\n",
        "            1e-3))\n",
        "\n",
        "    # SimCLR training\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss_meter = AverageMeter(\"SimCLR_loss\")\n",
        "        train_bar = tqdm(train_loader)\n",
        "        total_loss = 0\n",
        "        for img_in, img_out in zip(train_loader, train_out_loader):\n",
        "            x_in, labels_in = img_in\n",
        "            x_out, labels_out = img_out\n",
        "            sizes = x_in.size()\n",
        "            sizes_out = x_out.size()\n",
        "            x_in = x_in.view(sizes[0] * 2, sizes[2], sizes[3], sizes[4]).cuda(non_blocking=True)\n",
        "            x_out = x_out.view(sizes[0] * 2, sizes[2], sizes[3], sizes[4]).cuda(non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            feature_in, rep_in = model(x_in)\n",
        "            feature_out, rep_out = model(x_out)\n",
        "            loss = nt_xent(rep_in, rep_out, temperature)\n",
        "            total_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            loss_meter.update(loss.item(), x_in.size(0))\n",
        "        print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch, loss_meter.avg))\n",
        "#         train_bar.set_description(\"Train epoch {}, SimCLR loss: {:.4f}\".format(epoch, loss_meter.avg))\n",
        "\n",
        "        # save checkpoint very log_interval epochs\n",
        "        if epoch >= log_interval and epoch % log_interval == 0:\n",
        "            logger.info(\"==> Save checkpoint. Train epoch {}, SimCLR loss: {:.4f}\".format(epoch, loss_meter.avg))\n",
        "            torch.save(model.state_dict(), 'CV_Project/simclr/simclr_ours_{}_epoch{}.pt'.format(backbone, epoch + 400))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60MCZBz9Bs0e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}